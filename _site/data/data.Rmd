
```{r}
library(httr)
library(jsonlite)
library(dplyr)
library(tidyr)
library(ggplot2)
library(gridExtra)
library(kableExtra)
library(GGally)
```

# Data Collection and Wrangling

```{r}
anime_data <- list()

for (y in 2015:2024) {
  for (s in c('Winter', 'Spring', 'Summer', 'Fall')) {
    page <- 1
    while (TRUE) {
      response <- GET(
        paste0("https://api.jikan.moe/v4/seasons/", y, "/", tolower(s), "?page=", page)
      )
      
      if (status_code(response) == 200) {
        data <- fromJSON(content(response, "text"))
        
        anime_list <- data$data |>
          mutate(title_english = coalesce(title_english, title), year = coalesce(year, y)) |>
          select(mal_id, title_english, type, source, airing, year, rating, 
            score, members, favorites,
            # producers, licensors,
            studios, genres) |>
          mutate(
            # producers = sapply(producers, function(x) paste(x$name, collapse = ", ")),
            # licensors = sapply(licensors, function(x) paste(x$name, collapse = ", ")),
            studios = sapply(studios, function(x) paste(x$name, collapse = ", ")),
            genres = sapply(genres, function(x) paste(x$name, collapse = ", "))
          )
        
        anime_data <- append(anime_data, list(anime_list))
        
        total_pages <- ceiling(data$pagination$items$total / data$pagination$items$per_page)
        
        if (page >= total_pages) {
          break
        } else {
          page <- page + 1
        }
      } else {
        message(paste("Failed to fetch data for", year, season, "on page", page, ":", status_code(response)))
        print(paste0("https://api.jikan.moe/v4/seasons/", year, "/", season))
      }
      Sys.sleep(1)
    }
  }
}

anime_data <- do.call(rbind, anime_data)
```

```{r}
# Optional: Save the raw extracted data in a csv file
# write.csv(anime_data, file = "mal_anime_2015_2024_raw.csv", row.names = FALSE)
```

```{r}
# Optional: read the raw extracted data from our .csv file
# anime_data <- read.csv("mal_anime_2015_2024_raw.csv")
```

```{r}
# Check for duplicated entries
duplicates <- anime_data[duplicated(anime_data$mal_id), ]
print(duplicates)
```

# Data Cleaning

```{r}
# 1. Remove duplicates and remove mal_id column
anime_data <- anime_data |>
  distinct(mal_id, .keep_all = TRUE) |>
  select(-c(mal_id))
```

```{r}
# 2. Filter the entries to what we consider an "anime" in the research question,
#    which are animated shows with theatrical or television broadcast

# Check types of entries
unique(anime_data$type)

# Filter based on the values of type
anime_data <- anime_data |>
  filter(type %in% c("TV", "Movie"))
```

```{r}
# 3. Remove currently airing anime
anime_data <- anime_data |>
  filter(!airing) |>
  select(-c(airing))
```

```{r}
# 4. Data reformating: NA values for studios, genres, and source;
#    Mutate year to integer
anime_data <- anime_data |>
  mutate(
    studios = na_if(studios, ""),
    genres = na_if(genres, ""),
    source = na_if(source, "Unknown"),
    year = as.integer(year)
  )

# Check NA values
colSums(is.na(anime_data))
```

```{r}
# 4. Remove NA Values
anime_data <- anime_data |>
  filter(!is.na(score)) |>
  filter(!is.na(rating)) |>
  filter(!is.na(studios)) |>
  filter(!is.na(genres))
```

```{r}
# Final dimension of anime_data
dim(anime_data)
```

```{r}
# Save the cleaned data to a .csv file
write.csv(anime_data, file = "mal_anime_2015_2024.csv", row.names = FALSE)
```

```{r}
# Optional: read the cleaned data from our .csv file
# anime_data <- read.csv(file = "mal_anime_2015_2024.csv")
```